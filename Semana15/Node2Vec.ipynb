{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6aeea70-dccf-479d-89bd-e2a2667f7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metricas\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058e332-af61-4901-9a42-d2ff8a7ae826",
   "metadata": {},
   "source": [
    "## Dataset de CORA\n",
    "\n",
    "Este dataset contiene dos archivos. El primero es una base de datos de papers que citan a otros papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3064a4d-8427-4b15-ae6c-cd06c56db5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>103482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>103515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1050679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>1103960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>853116</td>\n",
       "      <td>19621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>853116</td>\n",
       "      <td>853155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>853118</td>\n",
       "      <td>1140289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>853155</td>\n",
       "      <td>853118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>954315</td>\n",
       "      <td>1155073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target   source\n",
       "0         35     1033\n",
       "1         35   103482\n",
       "2         35   103515\n",
       "3         35  1050679\n",
       "4         35  1103960\n",
       "...      ...      ...\n",
       "5424  853116    19621\n",
       "5425  853116   853155\n",
       "5426  853118  1140289\n",
       "5427  853155   853118\n",
       "5428  954315  1155073\n",
       "\n",
       "[5429 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citas = pd.read_csv('cora/cora.cites',sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"target\", \"source\"])\n",
    "\n",
    "citas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a978ec-4d8c-41e4-8075-aa0af9b2bc29",
   "metadata": {},
   "source": [
    "El segundo archivo contiene informacién de muchas palabras (términos) asociadas a cada paper, y además una categoría. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b177b18b-ba7c-457b-96c9-a8a3a9470357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>word_0</th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>...</th>\n",
       "      <th>word_1424</th>\n",
       "      <th>word_1425</th>\n",
       "      <th>word_1426</th>\n",
       "      <th>word_1427</th>\n",
       "      <th>word_1428</th>\n",
       "      <th>word_1429</th>\n",
       "      <th>word_1430</th>\n",
       "      <th>word_1431</th>\n",
       "      <th>word_1432</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1106406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>1128975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>1128977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>1128978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>117328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Case_Based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>24043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  word_0  word_1  word_2  word_3  word_4  word_5  word_6  \\\n",
       "0        31336       0       0       0       0       0       0       0   \n",
       "1      1061127       0       0       0       0       0       0       0   \n",
       "2      1106406       0       0       0       0       0       0       0   \n",
       "3        13195       0       0       0       0       0       0       0   \n",
       "4        37879       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2703   1128975       0       0       0       0       0       0       0   \n",
       "2704   1128977       0       0       0       0       0       0       0   \n",
       "2705   1128978       0       0       0       0       0       0       0   \n",
       "2706    117328       0       0       0       0       1       0       0   \n",
       "2707     24043       0       0       0       0       0       0       0   \n",
       "\n",
       "      word_7  word_8  ...  word_1424  word_1425  word_1426  word_1427  \\\n",
       "0          0       0  ...          0          0          1          0   \n",
       "1          0       0  ...          0          1          0          0   \n",
       "2          0       0  ...          0          0          0          0   \n",
       "3          0       0  ...          0          0          0          0   \n",
       "4          0       0  ...          0          0          0          0   \n",
       "...      ...     ...  ...        ...        ...        ...        ...   \n",
       "2703       0       0  ...          0          0          0          0   \n",
       "2704       0       0  ...          0          0          0          0   \n",
       "2705       0       0  ...          0          0          0          0   \n",
       "2706       0       0  ...          0          0          0          0   \n",
       "2707       0       0  ...          0          0          0          0   \n",
       "\n",
       "      word_1428  word_1429  word_1430  word_1431  word_1432  \\\n",
       "0             0          0          0          0          0   \n",
       "1             0          0          0          0          0   \n",
       "2             0          0          0          0          0   \n",
       "3             0          0          0          0          0   \n",
       "4             0          0          0          0          0   \n",
       "...         ...        ...        ...        ...        ...   \n",
       "2703          0          0          0          0          0   \n",
       "2704          0          0          0          0          0   \n",
       "2705          0          0          0          0          0   \n",
       "2706          0          0          0          0          0   \n",
       "2707          0          0          0          0          0   \n",
       "\n",
       "                     subject  \n",
       "0            Neural_Networks  \n",
       "1              Rule_Learning  \n",
       "2     Reinforcement_Learning  \n",
       "3     Reinforcement_Learning  \n",
       "4      Probabilistic_Methods  \n",
       "...                      ...  \n",
       "2703      Genetic_Algorithms  \n",
       "2704      Genetic_Algorithms  \n",
       "2705      Genetic_Algorithms  \n",
       "2706              Case_Based  \n",
       "2707         Neural_Networks  \n",
       "\n",
       "[2708 rows x 1435 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###informacion de los papers de acuerdo a loas palabras que mencionan, junto a su paper id y el tema general\n",
    "\n",
    "column_names = [\"paper_id\"] + [f\"word_{idx}\" for idx in range(1433)] + [\"subject\"]\n",
    "papers = pd.read_csv(\n",
    "    'cora/cora.content', sep=\"\\t\", names=column_names,\n",
    ")\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cfc596-c537-4697-8ed2-34f59fa6178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject\n",
      "Neural_Networks           818\n",
      "Probabilistic_Methods     426\n",
      "Genetic_Algorithms        418\n",
      "Theory                    351\n",
      "Case_Based                298\n",
      "Reinforcement_Learning    217\n",
      "Rule_Learning             180\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(papers.subject.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f8016e-a8ae-46d4-9d63-9b1eddfd31e1",
   "metadata": {},
   "source": [
    "Vamos a pasar estos subjects a números, y armar los paper_id para que sean consecutivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e9f237-3634-4ab2-b1a1-2c225c983942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = sorted(papers[\"subject\"].unique())\n",
    "class_idx = {name: id for id, name in enumerate(class_values)}\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}\n",
    "\n",
    "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
    "citas[\"source\"] = citas[\"source\"].apply(lambda name: paper_idx[name])\n",
    "citas[\"target\"] = citas[\"target\"].apply(lambda name: paper_idx[name])\n",
    "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f9df98-a551-455a-91d0-68fbc92b1716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>1873</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>1873</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>1874</td>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>1876</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>1897</td>\n",
       "      <td>2707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  source\n",
       "0          0      21\n",
       "1          0     905\n",
       "2          0     906\n",
       "3          0    1909\n",
       "4          0    1940\n",
       "...      ...     ...\n",
       "5424    1873     328\n",
       "5425    1873    1876\n",
       "5426    1874    2586\n",
       "5427    1876    1874\n",
       "5428    1897    2707\n",
       "\n",
       "[5429 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3932b5ee-2f72-459c-97d2-92a70e75fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### solo para guardar los feature names de las cosas que van a ser nuestro dataset para entrenar\n",
    "feature_names = list(set(papers.columns) - {\"paper_id\", \"subject\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61c3ea-3222-417c-a1bf-9e7018a645a8",
   "metadata": {},
   "source": [
    "Nuestra tarea consiste en predecir la línea \"subject\" (el tema del paper), basándonos por ahora solo en el vector de ocurrencias de palabras. Con esto, dividimos el set de training y test en una matriz x y un vector y con los subjects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcaae22-b4b5-406f-914e-149c3c10b0b7",
   "metadata": {},
   "source": [
    "### Un primer clasificador\n",
    "\n",
    "Vamos a intentar predecir el subject de cada paper, usando solo la información en el dataframe de papers (no las citas). Vamos a usar RandomForest, y como métrica el score F1. Como esta clasificación es multiclase, tomamos el promedio de los scores F1 de cada clase (esto corresponde al scoring f1_macro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71facfb3-5e59-4569-8bb2-c996e92b4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8b4cb11-eb7a-4303-b155-f2c840db6f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73340208, 0.74247913, 0.70065171, 0.7166704 , 0.72301317])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rf = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=13), papers[feature_names], papers[\"subject\"], scoring='f1_macro')\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce6362-afc3-4a9f-99eb-f0135d5fdf98",
   "metadata": {},
   "source": [
    "### Agregando información de citas\n",
    "\n",
    "Lo primero es usar networkx, una librería de grafos, para almacenar nuestro grafo en memoria. Luego vamos a llamar a Node2Vec para conseguir embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d6c71a-9916-43ef-9146-52008fcdc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96e168ef-eae9-4384-8456-0da96b896c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### armamos un grafo dirigido con la estructura de citas\n",
    "G = nx.from_pandas_edgelist(citas, source=\"source\", target=\"target\",create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f1657a7-29d3-4273-b6e4-afc5c0e06cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### vamos a condensar la información de las palabras del dataframe paper en una sola dimensión, \n",
    "### la que usaremos como el peso de cada nodo para Node2Vec. \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff8f32cb-5703-4e1a-9375-269013927f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "\n",
    "Features_1D = pca.fit_transform(papers[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be212634-fcbe-4c88-9bc5-8d095f48f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "### y agregamos esa info al dataframe de papers. \n",
    "papers[\"weight\"] = Features_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e45ded68-864b-4648-a1f3-84f2e4522fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ahora agregamos la información de cada nodo a nuestro grafo. Solo agregamos el peso \n",
    "\n",
    "subjects_dict = dict(zip(papers['paper_id'], papers['weight']))\n",
    "nx.set_node_attributes(G, subjects_dict, 'weight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf58883-ae54-44d2-bf78-cbaf4517866b",
   "metadata": {},
   "source": [
    "Podemos imprimir valores nodo a nodo usando networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6262bf80-ee8c-49ca-b42d-95e6c9ae6c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 21 data: {'weight': 0.7571532981634186}\n",
      "Node 21 neighbors: [0, 557, 582]\n"
     ]
    }
   ],
   "source": [
    "for node_id in G.nodes:\n",
    "    node_data = G.nodes[node_id]\n",
    "    print(f\"Node {node_id} data: {node_data}\")\n",
    "\n",
    "    neighbors = list(G.neighbors(node_id))\n",
    "    print(f\"Node {node_id} neighbors: {neighbors}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a84048-a297-4fe7-84c9-adac71cdaffa",
   "metadata": {},
   "source": [
    "Ahora, ya con nuestro grafo, podemos llamar a Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f26cbc4-ef8a-4728-93be-8aa77e13fc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e503f38f95364829b5c903549aa66614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|████████████████| 20/20 [00:00<00:00, 68.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "### dimensions es el tamaño de los features. Walk_length el tamaño de las caminatas, y \n",
    "### num_walks la cantidad de caminatas. \n",
    "node2vec = Node2Vec(G, dimensions=16, walk_length=10, num_walks=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba6ba436-b9a4-4f52-b146-03935980a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Con fit calculamos embeddings. Min_count y batch_words son parametros heredados de\n",
    "### Word2vec, pero instanciados aca de forma mas pequeña. \n",
    "\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f150c40-44ea-4b95-a14d-8f1b4c95d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72d19e95-e4c5-4f0d-bb9d-d20b64ac0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      paper_id     dim_0     dim_1     dim_2     dim_3     dim_4     dim_5  \\\n",
      "0           21 -0.694267 -0.357350  1.640686  0.749505  0.525538  0.355988   \n",
      "1            0  0.073137  0.523458  1.899398  2.115041  0.099030 -0.209619   \n",
      "2          905 -0.209860  0.036354  1.168403  0.732985  0.181481  0.004719   \n",
      "3          906 -0.036907 -0.418786  1.743310  0.917336 -0.022319  0.291986   \n",
      "4         1909 -0.646281 -0.202158  0.631465  0.148104  0.046897 -0.050843   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2703      2585  0.001337  0.006236  0.703431 -0.338559  0.226602  0.469466   \n",
      "2704      1871 -1.794383 -0.476002  0.450609  2.387101  1.451134  1.694079   \n",
      "2705      1876 -1.137313 -0.794808  0.136642  1.496496  0.818069  1.295134   \n",
      "2706      1872 -1.622827 -0.370402  0.730027  2.495121  1.031816  1.666858   \n",
      "2707      1874 -0.985864 -0.588732  0.127847  1.381832  0.630383  1.058639   \n",
      "\n",
      "         dim_6     dim_7     dim_8     dim_9    dim_10    dim_11    dim_12  \\\n",
      "0    -0.009519 -0.086626  0.389811  0.455843 -0.371201 -1.008681  0.939714   \n",
      "1    -0.673513  0.862606  0.026531  0.138784  0.021262 -1.260519  1.428783   \n",
      "2     0.312220 -0.584569 -0.127032  0.505439 -0.411895 -0.699263  0.999681   \n",
      "3     0.330630 -0.366988 -0.306977  1.033060 -0.400840 -1.090304  1.608153   \n",
      "4     0.064803 -0.816676  0.341873  0.094401  0.078522 -0.225718  0.057357   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2703  0.601494 -0.044188 -0.345638  0.525368 -0.391643 -0.489862 -0.255773   \n",
      "2704  0.615756 -0.491274  1.099401  0.248166 -0.253207 -0.330868 -0.513465   \n",
      "2705  0.809693 -0.304984  0.699521 -0.173227  0.039263 -0.388165 -0.089671   \n",
      "2706  0.707343 -0.092928  1.552730  0.473767 -0.168760 -0.241919 -0.871185   \n",
      "2707  0.740223 -0.325438  0.590985 -0.084195  0.062037 -0.290404 -0.119914   \n",
      "\n",
      "        dim_13    dim_14    dim_15  \n",
      "0    -0.313916 -0.471765  1.149871  \n",
      "1    -2.761952 -0.650952  1.179247  \n",
      "2    -0.981996 -0.610595  0.204903  \n",
      "3    -1.234432 -0.946626  0.167014  \n",
      "4    -0.678845  0.065690  0.347782  \n",
      "...        ...       ...       ...  \n",
      "2703 -0.497748  0.481954  0.058855  \n",
      "2704 -1.349640  0.223590  2.030225  \n",
      "2705 -1.019488  0.129515  1.460956  \n",
      "2706 -1.297651  0.548073  2.188553  \n",
      "2707 -0.824534  0.154208  1.370598  \n",
      "\n",
      "[2708 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "### Armamos un dataframe con los embeddings y lo concatenamos al de papers\n",
    "\n",
    "columns_embedding =['paper_id'] + ['dim_'+str(i) for i in range(0,16)]\n",
    "df = pd.DataFrame(\n",
    "[(int(node), *values) for node, values in embeddings.items()], columns=columns_embedding)\n",
    "\n",
    "papers_embeddings = pd.merge(df,papers,on='paper_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d95caab-0ced-46dc-956b-5b7cc41ea31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77466769, 0.7503533 , 0.7786987 , 0.7294128 , 0.717947  ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### y ahora vemos que tal el clasificador cuando agregamos información de \n",
    "### las citas\n",
    "\n",
    "datos_utiles = feature_names + ['dim_'+str(i) for i in range(0,16)]\n",
    "\n",
    "score_rf = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=13), papers_embeddings[datos_utiles], papers_embeddings[\"subject\"], scoring='f1_macro')\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30224b1a-4feb-4153-8b6b-46fcd0278dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
